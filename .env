# Sample RAGS_tool configuration
# Copy or adjust these values before running the service.

QDRANT_URL=http://127.0.0.1:6333
QDRANT_API_KEY=
EMBEDDING_API_URL=http://127.0.0.1:8000/v1
EMBEDDING_API_KEY=sk-embed-xxx
EMBEDDING_MODEL=sdadas/mmlw-retrieval-roberta-large-v2
# Tokenizer spec: use tiktoken:<encoding> for OpenAI-compatible models,
# or hf:<model_name> for Hugging Face tokenizers.
# Example for sdadas/mmlw-retrieval-roberta-large-v2:
# EMBEDDING_TOKENIZER=hf:sdadas/mmlw-retrieval-roberta-large-v2
EMBEDDING_TOKENIZER=tiktoken:cl100k_base
EMBEDDING_DIM=1024
# Max tokens per single input to the embedding endpoint (safety cap)
EMBEDDING_MAX_TOKENS=300
# Prefixes for retrieval-style embedding models (defaults match
# sdadas/mmlw-retrieval-roberta-large-v2). Set to empty for models
# that do not expect instruction prefixes (e.g., some BGE variants).
EMBEDDING_QUERY_PREFIX="query: "
EMBEDDING_PASSAGE_PREFIX="passage: "
SUMMARY_API_URL=http://127.0.0.1:8001/v1
SUMMARY_API_KEY=sk-summary-xxx
SUMMARY_MODEL=gpt-oss:20b
SUMMARY_SYSTEM_PROMPT="Jesteś zwięzłym ekstrakcyjnym streszczaczem."
SUMMARY_PROMPT="Streść poniższy tekst w maks. 5 zdaniach. Wypisz też sekcje: 'TITLE' (krótki jednoznaczny tytuł, preferuj pierwszą linię lub numer dokumentu; jeśli masz wątpliwości preferuj Zarządzenie / Uchwała; max 50 znaków, zawsze w mianowniku), 'SIGNATURE' (10–20 lematów kluczowych), 'ENTITIES' (nazwy własne/akronimami/ID/zakresy dat), 'DATE' (data wprowadzenia/ogłoszenia dokumentu; preferuj format YYYY-MM-DD lub YYYY; wpisz dokładnie 'brak', jeśli brak informacji) oraz 'REPLACEMENT' (krótkie tytuły aktów zastępowanych, zawsze w mianowniku; może składać się jedynie z krótkich tytułów dokumentów zastępowanych, jeśli ustalisz numer dokumentu po nim nie dodawaj nic, jeśli dokument nosi miano jednolity wypisz wszystkie tytuły dokumentów które ujednolica, separator ';'; max 50 znaków na pozycję; wpisz dokładnie 'brak', jeśli brak informacji). Bez komentarzy.\n\nFORMAT:\nTITLE: ...\nSUMMARY: ...\nSIGNATURE: lemma1, lemma2, ...\nENTITIES: ...\nDATE: ...\nREPLACEMENT: ...\n\nTEKST:\n"
SUMMARY_PROMPT_JSON="Zwróć wyłącznie poprawny JSON bez komentarzy i bez kodu. Klucze: 'title' (string; krótki jednoznaczny tytuł, preferuj pierwszą linię lub numer dokumentu; jeśli masz wątpliwości preferuj Zarządzenie / Uchwała; max 50 znaków, zawsze w mianowniku), 'summary' (string; max 5 zdań po polsku), 'signature' (lista 10–20 lematów kluczowych jako strings), 'entities' (lista stringów z nazwami własnymi/akronimami/ID/zakresami dat), 'doc_date' (string; data wprowadzenia/ogłoszenia dokumentu w formacie 'YYYY-MM-DD' lub 'YYYY-MM' lub 'YYYY'; jeśli brak informacji wpisz dokładnie 'brak'), 'replacement' (string; krótkie tytuły dokumentów zastępowanych, zawsze w mianowniku; może składać się jedynie z krótkich tytułów dokumentów zastępowanych, jeśli ustalisz numer dokumentu po nim nie dodawaj nic, jeśli dokument nosi miano jednolity wypisz wszystkie tytuły dokumentów które ujednolica, separator ';'; max 50 znaków na pozycję; wpisz dokładnie 'brak', jeśli brak informacji)."
SUMMARY_JSON_MODE=true
COLLECTION_NAME=rags_tool
VECTOR_STORE_DIR=/app/.rags_tool_store
DEBUG=true
SEARCH_TOOL_DESCRIPTION="Dwustopniowe wyszukiwanie RAG (streszczenia → pełne treści) zwracające krótkie, cytowalne bloki ('blocks') jako materiał dowodowy do odpowiedzi. Endpoint nie służy do liczenia ani listowania dokumentów.\n\nZakres domyślny:\n- Gdy 'mode' = 'auto', traktuj zapytanie jako 'current' (obowiązujące akty), chyba że kontekst wyraźnie wskazuje inaczej: \n  • 'archiwal*', 'stara', 'wersja z ...' lub konkretne lata → użyj 'archival',\n  • 'wszystkie', 'cała historia', 'pełen zakres' → użyj 'all'.\n\nZachowanie:\n- Etap 1 selekcjonuje dokumenty po streszczeniach (hybryda dense + TF‑IDF, opcjonalny MMR).\n- Etap 2 wyszukuje w chunkach wybranych dokumentów i buduje zmergowane sekcje ('blocks').\n- Opcjonalny reranker porządkuje gotowe bloki.\n\nJak wołać (dla modeli LLM):\n- Podawaj 2–8 zwięzłych wariantów 'query' (tytuły/sygnatury/datacje/słowa kluczowe).\n- Preferuj wynik 'result_format' = 'blocks' (domyślnie).\n- Utrzymuj 'top_k' w zakresie 5–10; 'top_m' max. 60; kontroluj dominację jednego dokumentu 'per_doc_limit'.\n- Jeśli masz encje (nazwy/ID/lata/cytaty), przekaż w 'entities' i wybierz 'entity_strategy' (auto/boost/must_any/must_all/exclude).\n\nCzego NIE robić tym endpointem:\n- Nie proś o liczbę dokumentów ani same listy doc_id/tytułów. Do tego używaj: \n  • POST /browse/count — liczba dokumentów‑kandydatów (Stage‑1),\n  • POST /browse/doc-ids — lista doc_id + meta (tytuł, data, is_active),\n  • POST /browse/facets — proste rozkłady (is_active, rok).\n\nUżywaj wyłącznie języka polskiego. Cały korpus oraz metadane są po polsku."

# Search configuration
# If true, bypass Stage 1 (summaries) and search full corpus directly in Stage 2.
# Admin-only static switch (no API override).
# SEARCH_SKIP_STAGE1_DEFAULT=false

# --- Hybryda 2‑query (bez ciężkiego TF‑IDF w payloadzie) ---
# Gdy włączone, Stage 1 i Stage 2 wykonują dwa zapytania do Qdrant:
#  - dense: po wektorach gęstych (CONTENT_/SUMMARY_VECTOR_NAME)
#  - sparse: po wektorach rzadkich TF‑IDF (CONTENT_/SUMMARY_SPARSE_NAME)
# Następnie wyniki są normalizowane i łączone po stronie aplikacji (hybryda lub RRF).
# Zalety: znacząco mniejsze payloady i niższe zużycie CPU Qdrant; jakość bez zmian.
# Wymagania: skonfigurowane named sparse vectors oraz lokalny TF‑IDF do generowania zapytań.
# Bezpieczny fallback: przy braku sparse — używany jest tylko dense.
SEARCH_DUAL_QUERY_SPARSE=false

# Parametry fuzji dla 2‑query (obowiązują również w klasycznej hybrydzie):
#  - DUAL_QUERY_RRF_K: stała RRF (większa → łagodniejsza penalizacja dalszych pozycji)
#  - DUAL_QUERY_OVERSAMPLE: współczynnik nadpróbkowania puli kandydatów przed MMR
#  - DUAL_QUERY_DENSE_FOR_MMR: do redundancji w MMR używa tylko wektorów gęstych (zalecane)
DUAL_QUERY_RRF_K=60
DUAL_QUERY_OVERSAMPLE=2
DUAL_QUERY_DENSE_FOR_MMR=true

# Minimalizacja payloadu (ograniczanie pól w with_payload). Zalecane: true.
# Uwaga: automatycznie włączone i kompatybilne z różnymi wersjami klienta Qdrant.
SEARCH_MINIMAL_PAYLOAD=true

# Batchowanie pobrań sekcji: jedna kwerenda scroll per dokument, obejmująca
# wszystkie potrzebne sekcje (prefiksowe dopasowanie po section_path_prefixes).
# Zalecane: true.
BATCH_SECTION_FETCH=true

# --- Entities-aware search (boosting + opcjonalne filtry) ---
# Siła miękkiego bonusu dopasowań encji w Etapie 1 i 2
ENTITY_BOOST_STAGE1=0.15
ENTITY_BOOST_STAGE2=0.10
# Gdy brak 'entities' w zapytaniu, backend spróbuje wyciągnąć encje heurystycznie
AUTO_EXTRACT_QUERY_ENTITIES=true

# Chunking defaults (token-based). Adjust to embedding model capacity.
# For sdadas/mmlw-retrieval-roberta-large-v2 (max ~512, 446 for WordPiece tokens),
# smaller chunks reduce truncation; tune as needed.
CHUNK_TOKENS=446 
CHUNK_OVERLAP=50
# Possible values: chapter, par, ust, pkt, lit (default ust; choose higher level to merge broader sections)
SECTION_MERGE_LEVEL=ust

# --- RERANKER (OpenAI‑compatible). Pozostaw puste, aby wyłączyć. ---
# Ustaw bazę BEZ '/v1'. Klient automatycznie użyje '/v1/rerank'.
RANKER_BASE_URL=
RANKER_API_KEY=
RANKER_MODEL=sdadas/polish-reranker-roberta-v3
RERANK_TOP_N=50
RETURN_TOP_K=5
RANKER_SCORE_THRESHOLD=0.2
RANKER_MAX_LENGTH=2048

GOLDEN_LLM_BASE_URL=https://ai.p.lodz.pl/api
GOLDEN_LLM_API_KEY=sk-key
GOLDEN_LLM_MODEL=model_id
EVAL_CLEAN=1
EVAL_FINAL_JSON_KEY=final_answerexport
EVAL_BASE_URL=https://ai.test.p.lodz.pl/api
EVAL_API_KEY=sk-key
EVAL_MODEL=model_id
