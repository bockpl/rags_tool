# Sample RAGS_tool configuration
# Copy or adjust these values before running the service.

QDRANT_URL=http://127.0.0.1:6333
QDRANT_API_KEY=
EMBEDDING_API_URL=http://127.0.0.1:8000/v1
EMBEDDING_API_KEY=sk-embed-xxx
EMBEDDING_MODEL=sdadas/mmlw-retrieval-roberta-large-v2
# Tokenizer spec: use tiktoken:<encoding> for OpenAI-compatible models,
# or hf:<model_name> for Hugging Face tokenizers.
# Example for sdadas/mmlw-retrieval-roberta-large-v2:
# EMBEDDING_TOKENIZER=hf:sdadas/mmlw-retrieval-roberta-large-v2
EMBEDDING_TOKENIZER=tiktoken:cl100k_base
EMBEDDING_DIM=1024
# Max tokens per single input to the embedding endpoint (safety cap)
EMBEDDING_MAX_TOKENS=300
# Prefixes for retrieval-style embedding models (defaults match
# sdadas/mmlw-retrieval-roberta-large-v2). Set to empty for models
# that do not expect instruction prefixes (e.g., some BGE variants).
EMBEDDING_QUERY_PREFIX="query: "
EMBEDDING_PASSAGE_PREFIX="passage: "
SUMMARY_API_URL=http://127.0.0.1:8001/v1
SUMMARY_API_KEY=sk-summary-xxx
SUMMARY_MODEL=gpt-oss:20b
SUMMARY_JSON_MODE=true
COLLECTION_NAME=rags_tool
VECTOR_STORE_DIR=/app/.rags_tool_store
DEBUG=true

# Search configuration
# If true, bypass Stage 1 (summaries) and search full corpus directly in Stage 2.
# Admin-only static switch (no API override).
# SEARCH_SKIP_STAGE1_DEFAULT=false

# --- Hybryda 2‑query (bez ciężkiego TF‑IDF w payloadzie) ---
# Gdy włączone, Stage 1 i Stage 2 wykonują dwa zapytania do Qdrant:
#  - dense: po wektorach gęstych (CONTENT_/SUMMARY_VECTOR_NAME)
#  - sparse: po wektorach rzadkich TF‑IDF (CONTENT_/SUMMARY_SPARSE_NAME)
# Następnie wyniki są normalizowane i łączone po stronie aplikacji (hybryda lub RRF).
# Zalety: znacząco mniejsze payloady i niższe zużycie CPU Qdrant; jakość bez zmian.
# Wymagania: skonfigurowane named sparse vectors oraz lokalny TF‑IDF do generowania zapytań.
# Bezpieczny fallback: przy braku sparse — używany jest tylko dense.
SEARCH_DUAL_QUERY_SPARSE=false

# Parametry fuzji dla 2‑query (obowiązują również w klasycznej hybrydzie):
#  - DUAL_QUERY_RRF_K: stała RRF (większa → łagodniejsza penalizacja dalszych pozycji)
#  - DUAL_QUERY_OVERSAMPLE: współczynnik nadpróbkowania puli kandydatów przed MMR
#  - DUAL_QUERY_DENSE_FOR_MMR: do redundancji w MMR używa tylko wektorów gęstych (zalecane)
DUAL_QUERY_RRF_K=60
DUAL_QUERY_OVERSAMPLE=2
DUAL_QUERY_DENSE_FOR_MMR=true

# Minimalizacja payloadu (ograniczanie pól w with_payload). Zalecane: true.
# Uwaga: automatycznie włączone i kompatybilne z różnymi wersjami klienta Qdrant.
SEARCH_MINIMAL_PAYLOAD=true

# Batchowanie pobrań sekcji: jedna kwerenda scroll per dokument, obejmująca
# wszystkie potrzebne sekcje (prefiksowe dopasowanie po section_path_prefixes).
# Zalecane: true.
BATCH_SECTION_FETCH=true

# --- Entities-aware search (boosting + opcjonalne filtry) ---
# Siła miękkiego bonusu dopasowań encji w Etapie 1 i 2
ENTITY_BOOST_STAGE1=0.15
ENTITY_BOOST_STAGE2=0.10
# Gdy brak 'entities' w zapytaniu, backend spróbuje wyciągnąć encje heurystycznie
AUTO_EXTRACT_QUERY_ENTITIES=true

# Chunking defaults (token-based). Adjust to embedding model capacity.
# For sdadas/mmlw-retrieval-roberta-large-v2 (max ~512, 446 for WordPiece tokens),
# smaller chunks reduce truncation; tune as needed.
CHUNK_TOKENS=446 
CHUNK_OVERLAP=50
# Possible values: chapter, par, ust, pkt, lit (default ust; choose higher level to merge broader sections)
SECTION_MERGE_LEVEL=ust

# --- RERANKER (OpenAI‑compatible). Pozostaw puste, aby wyłączyć. ---
# Ustaw bazę BEZ '/v1'. Klient automatycznie użyje '/v1/rerank'.
RANKER_BASE_URL=
RANKER_API_KEY=
RANKER_MODEL=sdadas/polish-reranker-roberta-v3
RERANK_TOP_N_MAX=50
RETURN_TOP_K_MAX=50
RANKER_SCORE_THRESHOLD=0.9
RANKER_HARD_THRESHOLD=0.65
RANKER_MAX_LENGTH=2048

GOLDEN_LLM_BASE_URL=https://ai.p.lodz.pl/api
GOLDEN_LLM_API_KEY=sk-key
GOLDEN_LLM_MODEL=model_id
EVAL_CLEAN=1
EVAL_FINAL_JSON_KEY=final_answerexport
EVAL_BASE_URL=https://ai.test.p.lodz.pl/api
EVAL_API_KEY=sk-key
EVAL_MODEL=model_id
